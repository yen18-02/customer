import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.ensemble import IsolationForest
from textblob import TextBlob
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import seaborn as sns
import io
import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize

st.set_page_config(page_title="Ph√¢n T√≠ch T√¢m L√Ω Ng∆∞·ªùi Ti√™u D√πng", layout="wide")
st.title("üìä Ph√¢n T√≠ch T√¢m L√Ω Ng∆∞·ªùi Ti√™u D√πng")

st.markdown("""
<style>
    .css-1d391kg {padding-top: 1rem;}
    .reportview-container .markdown-text-container { font-family: 'Arial'; font-size:16px; }
</style>
""", unsafe_allow_html=True)

uploaded_file = st.file_uploader("T·∫£i l√™n file CSV d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch", type="csv")

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)

    st.subheader("1. D·ªØ li·ªáu ban ƒë·∫ßu")
    st.dataframe(df.head())

    # Ph√¢n t√≠ch c·∫£m x√∫c
    st.subheader("2. Ph√¢n t√≠ch c·∫£m x√∫c t·ª´ ƒë√°nh gi√°")
    def get_sentiment(text):
        if pd.isnull(text):
            return 0
        return TextBlob(str(text)).sentiment.polarity

    df["SENTIMENT"] = df["COMMENT"].apply(get_sentiment)
    st.write("Ho√†n t·∫•t ph√¢n t√≠ch c·∫£m x√∫c.")

    # TF-IDF
    st.subheader("3. Ph√¢n t√≠ch TF-IDF")
    tfidf_vectorizer = TfidfVectorizer(max_features=100, stop_words='english')
    tfidf_matrix = tfidf_vectorizer.fit_transform(df['COMMENT'].fillna('').astype(str))
    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())
    st.write("T·ª´ kh√≥a ph·ªï bi·∫øn (TF-IDF):")
    st.write(tfidf_df.sum().sort_values(ascending=False).head(10))

    # WordCloud
    st.subheader("4. WordCloud t·ª´ b√¨nh lu·∫≠n")
    text = " ".join(df['COMMENT'].dropna().astype(str))
    wordcloud = WordCloud(width=800, height=400).generate(text)
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    st.pyplot(plt)

    # LDA
    #st.subheader("5. Ph√¢n t√≠ch ch·ªß ƒë·ªÅ (LDA)")
    #tokenized_docs = df['COMMENT'].dropna().apply(lambda x: word_tokenize(str(x).lower()))
    #dictionary = corpora.Dictionary(tokenized_docs)
    #corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]
    #lda_model = models.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=10)
    #topics = lda_model.print_topics(num_words=5)
    #for i, topic in topics:
    #    st.write(f"Ch·ªß ƒë·ªÅ {i+1}: {topic}")

    # PCA
    st.subheader("6. Gi·∫£m chi·ªÅu PCA v√† tr·ª±c quan h√≥a")
    scaler = StandardScaler()
    scaled_data = scaler.fit_transform(df.select_dtypes(include=np.number).fillna(0))
    pca = PCA(n_components=2)
    pca_result = pca.fit_transform(scaled_data)
    df['PCA1'] = pca_result[:, 0]
    df['PCA2'] = pca_result[:, 1]
    fig, ax = plt.subplots()
    sns.scatterplot(x='PCA1', y='PCA2', data=df, hue='SENTIMENT', ax=ax)
    st.pyplot(fig)

    # KMeans
    st.subheader("7. Ph√¢n c·ª•m kh√°ch h√†ng (KMeans)")
    kmeans = KMeans(n_clusters=3, random_state=42)
    df['CLUSTER'] = kmeans.fit_predict(scaled_data)
    st.bar_chart(df['CLUSTER'].value_counts())

    # Isolation Forest
    st.subheader("8. Ph√°t hi·ªán kh√°ch h√†ng b·∫•t th∆∞·ªùng")
    iso_forest = IsolationForest(contamination=0.05, random_state=42)
    df['OUTLIER'] = iso_forest.fit_predict(scaled_data)
    df['OUTLIER'] = df['OUTLIER'].map({1: 'B√¨nh th∆∞·ªùng', -1: 'B·∫•t th∆∞·ªùng'})
    st.dataframe(df[df['OUTLIER'] == 'B·∫•t th∆∞·ªùng'][['CUST_ID', 'OUTLIER']])

    # Chi·∫øn l∆∞·ª£c
    st.subheader("9. G·ª£i √Ω chi·∫øn l∆∞·ª£c theo c·ª•m kh√°ch h√†ng")
    def product_strategy(cluster_id):
        if cluster_id == 0:
            return "T·∫≠p trung c·∫£i ti·∫øn d·ªãch v·ª• h·∫≠u m√£i v√† h·ªó tr·ª£ kh√°ch h√†ng"
        elif cluster_id == 1:
            return "C·∫£i ti·∫øn ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m, gi√° h·ª£p l√Ω"
        else:
            return "ƒê·∫©y m·∫°nh qu·∫£ng c√°o, t·∫≠p trung v√†o ƒëi·ªÉm m·∫°nh s·∫£n ph·∫©m"

    df["G·ª¢I_√ù_CHI·∫æN_L∆Ø·ª¢C"] = df["CLUSTER"].apply(product_strategy)
    st.dataframe(df[["CUST_ID", "CLUSTER", "G·ª¢I_√ù_CHI·∫æN_L∆Ø·ª¢C"]].head(10))

    st.subheader("10. T·∫£i xu·ªëng k·∫øt qu·∫£")
    output_csv = df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="üì• T·∫£i file k·∫øt qu·∫£ (.csv)",
        data=output_csv,
        file_name='ket_qua_phan_tich.csv',
        mime='text/csv'
    )

else:
    st.warning("Vui l√≤ng t·∫£i l√™n file CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
