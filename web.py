import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.ensemble import IsolationForest
from textblob import TextBlob
from sklearn.feature_extraction.text import CountVectorizer
import io

st.set_page_config(page_title="Ph√¢n T√≠ch T√¢m L√Ω Ng∆∞·ªùi Ti√™u D√πng", layout="wide")
st.title("üìä Ph√¢n T√≠ch T√¢m L√Ω Ng∆∞·ªùi Ti√™u D√πng")

st.markdown("""
<style>
    .css-1d391kg {padding-top: 1rem;}
    .reportview-container .markdown-text-container { font-family: 'Arial'; font-size:16px; }
</style>
""", unsafe_allow_html=True)

uploaded_file = st.file_uploader("T·∫£i l√™n file CSV d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch", type="csv")

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)

    st.subheader("1. D·ªØ li·ªáu ban ƒë·∫ßu")
    st.dataframe(df.head())

    st.subheader("2. Ph√¢n t√≠ch c·∫£m x√∫c t·ª´ ƒë√°nh gi√°")
    def get_sentiment(text):
        if pd.isnull(text):
            return 0
        return TextBlob(str(text)).sentiment.polarity

    df["SENTIMENT"] = df["COMMENT"].apply(get_sentiment)
    st.write("Ho√†n t·∫•t ph√¢n t√≠ch c·∫£m x√∫c.")

    numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
    X = df[numeric_cols].fillna(0)

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    st.subheader("3. Ph√¢n c·ª•m kh√°ch h√†ng (KMeans)")
    kmeans = KMeans(n_clusters=3, random_state=42)
    df['CLUSTER'] = kmeans.fit_predict(X_scaled)
    st.bar_chart(df['CLUSTER'].value_counts())

    st.subheader("4. Ph√°t hi·ªán kh√°ch h√†ng b·∫•t th∆∞·ªùng (Isolation Forest)")
    iso_forest = IsolationForest(contamination=0.05, random_state=42)
    df['OUTLIER'] = iso_forest.fit_predict(X_scaled)
    df['OUTLIER'] = df['OUTLIER'].map({1: 'B√¨nh th∆∞·ªùng', -1: 'B·∫•t th∆∞·ªùng'})
    st.dataframe(df[df['OUTLIER'] == 'B·∫•t th∆∞·ªùng'][["CUST_ID", "OUTLIER"]])

    st.subheader("5. T·ª´ kh√≥a n·ªïi b·∫≠t trong ƒë√°nh gi√°")
    vectorizer = CountVectorizer(stop_words='english', max_features=10)
    X_words = vectorizer.fit_transform(df['COMMENT'].dropna().astype(str))
    keywords = vectorizer.get_feature_names_out()
    st.write(", ".join(keywords))

    st.subheader("6. G·ª£i √Ω chi·∫øn l∆∞·ª£c theo c·ª•m kh√°ch h√†ng")
    def product_strategy(cluster_id):
        if cluster_id == 0:
            return "T·∫≠p trung c·∫£i ti·∫øn d·ªãch v·ª• h·∫≠u m√£i v√† h·ªó tr·ª£ kh√°ch h√†ng"
        elif cluster_id == 1:
            return "C·∫£i ti·∫øn ch·∫•t l∆∞·ª£ng s·∫£n ph·∫©m, gi√° h·ª£p l√Ω"
        else:
            return "ƒê·∫©y m·∫°nh qu·∫£ng c√°o, t·∫≠p trung v√†o ƒëi·ªÉm m·∫°nh s·∫£n ph·∫©m"

    df["G·ª¢I_√ù_CHI·∫æN_L∆Ø·ª¢C"] = df["CLUSTER"].apply(product_strategy)
    st.dataframe(df[["CUST_ID", "CLUSTER", "G·ª¢I_√ù_CHI·∫æN_L∆Ø·ª¢C"]].head(10))

    st.subheader("7. T·∫£i xu·ªëng k·∫øt qu·∫£ ph√¢n t√≠ch")
    output_csv = df.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="üì• T·∫£i file k·∫øt qu·∫£ (.csv)",
        data=output_csv,
        file_name='ket_qua_phan_tich.csv',
        mime='text/csv'
    )
else:
    st.warning("Vui l√≤ng t·∫£i l√™n file CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")
